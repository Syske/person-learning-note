## 前言

业务背景和技术背景我们上次分享已经说过了，这里就不再赘述了，我们来开始今天的内容，主要包含以下内容：
- 项目方案概述：主流程概述；方案要点
- 各组件的关机流程概述

## 方案概述

因为我们项目都是基于`sofa-boot`（`springboot`）架构的，所以我们一开始考虑的就是构建一个`spring-boot-starter`，然后在`starter`中通过条件配置，来实现我们的关机逻辑，包括关机的流程控制、组件的动态配置（避免服务中没有某个组件，导致关机异常）、组件的监控等。

这样设计的好处是比较灵活，某个服务如果要支持优雅关机，只需要引入我们的`starter`即可，不需要进行二次开发，降低了适配的工作量，而且前期测试完成后，后期接入时，测试的工作量也大大降低，可以有效控制风险，当然这里有个前提条件是，各个服务用到的中间件版本要尽可能一致或者要相近，否则可能会有兼容性问题。

我们先看主流程：
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/911c7ab9-e03d-4d4f-913a-b42039c5d714.jpg)

### 优雅关机主流程

上次分享我们说过，`k8s`下`springboot`的优雅关机是从应用收到`SIGTERM`信号开始的，所以本次的优雅关机就是通过监听节点`SIGTERM`展开的，我们先看一个时序图（如果手机看不清楚，我可以分享源文件）：
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/5ee9724d-95d4-4b3d-98af-7d8e23c18f6d.jpg)

核心部分局部放大给大家看下：

![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/9a2a706b-6128-4d5d-a13c-9ba80cd2d80a.jpg)

优雅关机主流程如下：
1. `SIGTERM`监听器器收到信号，触发预关机逻辑
2. 预关机逻辑：
	- 将服务标记为不健康，让负载均衡逻辑生效（这里会等待5秒）
	- 按组件配置好的优先级，依次处理`Tomcat`、`rpc`提供者、`MQ`、线程池、`rpc`客户端
	- 关闭`springboot`上下文（`applicationContext`）

### 方案要点

#### 组件关机顺序

首先，第一个要考虑的其实就是关机组件顺序的问题，这个是要根据系统的使用的组件综合考虑的。以我们的服务为例，需要考虑优雅关机的组件有：
- `Tomcat`：处理前端的`rest`请求，关机时需要考虑处理中的请求，确保关机时，接收到的请求全部处理完成
- `RPC`：我们后端服务间通信基本都是这种方式，需要考虑服务提供者和客户端，两者的关闭时机是不同的。提供者是提供给外部服务的，可以考虑优先关闭；客户端用到的场景就比较多，比如`mq`、`rest`请求、线程池等场景下，所以需要放到最后关闭。
- `MQ`：这里只考虑消费者端，我们用到了两种消息队列：
	- 一种是`ActiveMQ`，基本上都是之前比较早的逻辑在使用；
	- 另一种是`RocketMQ`，新的业务都是这种方式，由于最开始针对这块我们自己封装了消费逻辑，所以优雅关机改造风险较大，加之封装逻辑内部有自己的优雅关机，所以本次我们只考虑了`@RocketMQMessageListener`场景。后面发现，封装的消费逻辑优雅关机优先级无法控制，后期还是要改造。
- 线程池：这里包括`springboot`自己的线程池、`tomcat`的线程池，以及我们自己手动定义的线程池

#### k8s要点

##### 容器健康检查

在实际测试过程中，我们发现多节点场景下，如果`k8s`不设置容器的健康检查，服务关机期间`rest`请求会出现`no endpoint`的报错，最终确定到问题是：

`k8s`在新节点容器没有起来的时候，就将服务标记为`ready`，实际服务还不可用，旧服务已经开始关闭，所以导致没有可用的服务节点。

开启容器健康检查后，`k8s`会在新的节点启动起来之后，再触发旧节点的关机流程，这时候才是真正的滚动发布。
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/8b31c6db-06a4-48b4-ae43-da8d514ef389.jpg)

##### 最大宽限期

这里再次强调下**最大宽限期**这个设置，默认只有`30`秒，如果在设置的时间内无法完成优雅关机，要考虑调整这个时间。服务内部也要根据这个时间，合理分配各个组件的关机等待时间。这个设置是可以支持针对指定的`pod`配置的：

```yaml
spec:
  terminationGracePeriodSeconds: 300  # 5分钟
  # 应用有完整5分钟处理SIGTERM
```


### 各个组件概述

下面我们介绍下各个组件的基本实现思路。首先是优先级问题，这个前面说了，我们的顺序是：`Tomcat`、`rpc`提供者、`MQ`、线程池、`rpc`客户端

我们就按这个顺序展开：

#### Tomcat

流程图如下：
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/abc4ac48-d1a0-43f5-b037-b1e0ed13ea13.jpg)

简单说下流程：
1. 暂停接受新请求：通过调用连接器的`pause`方法暂停，暂停后不再接受新的`rest`请求，当然在此之前，要先在网关层面移除这个节点，网关逻辑优先级要高于`Tomcat`。因为我们用的是`kong`网关，在`k8s`节点关机时，网关已经自动移除相关节点，所以本次方案不考虑网关。
2. 获取`Tomcat`线程池信息，调用`shutdown`方法，等待线程池中的任务完成；如果超时未完成（超时时间可以自行配置），强制关闭线程池，并打印日志
3. 关闭`Connector`连接器，关机完成

#### `RPC`提供者

`rpc`的提供者和`Tomcat`其实没有优先级区分，两者没有任何依赖关系，我们这次设计的实际是先关闭`Tomcat`，后关闭`rpc`提供者，实际上如果出于提升优雅关机效率的角度，可以通过多线程来同时触发，这个可以作为后续的优化点来考虑。

优雅关机流程如下：
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/91c98f68-336a-4823-901d-f73e0de44d75.jpg)

核心流程如下：
1. 将提供者标记为不可用：最开始考虑的是在服务提供者的拦截器中判断是否正在关机，关机则抛出异常，后面觉得不够友好，只打印了日志。这个可以根据自己的情况看是否校验。
2. 取消服务提供者注册：将所有提供者从注册中心将服务下线，`sofa-rpc`直接调用提供者的`unExport`方法即可。
3. 等待已经接受到的请求处理完成：不需要做什么，循环监测活跃的线程数即可。监控数据主要是处理中的请求数，这个是基于提供者的拦截器实现的。

#### MQ

这块分两种，`ActiveMQ`和`RocketMQ`，本身并没有区分优先级，但是逻辑上依然是串行的，所以优化点同`Tomcat`和`sofa-rpc`提供者。

##### RocketMQ

`rocketMQ`优雅关机流程图如下：
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/796cfac8-9441-49f8-87c4-8cef9fbaa314.jpg)

核心流程如下：
1. 停止所有消费者`DefaultRocketMQListenerContainer`：调用`stop`方法
2. 等待处理中的消息完成：这里由于无法拿到消息数量（需要调用阿里云的`sdk`能力），所以最终是判断活跃中的容器数量。

##### ActiveMQ

关机流程如下：
![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/6b5ddc4d-3369-4643-9626-8ef77d64335b.jpg)

核心流程如下：
1. 关闭所有消费者：调用`DefaultMessageListenerContainer`的`stop`方法
2. 等待处理中的消息完成：等待并监控活跃中的容器数量和消费者数量

#### 线程池

线程池涉及五种，分别是：
- `spring`任务调度器：就是`spring`的各种调度线程池（`ThreadPoolTaskScheduler`）
- `spring`线程池：`spring`中用到的各种`executor`(`ThreadPoolTaskExecutor`)
- 普通线程池：基于`jdk`的线程池，自定义的线程池（`ExecutorService`）
- 调度线程池：基于`jdk`的调度线程池（`ScheduledExecutorService`）
- `ForkJoinPool`：`jdk`的`ForkJoinPool`

流程图如下：

![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/201fd457-de09-40a9-8707-7eb274d7e644.jpg)

除了`ForkJoinPool`，其他线程池核心流程都差不多：
1. 关闭线程池：调用线程池`shutdown`方法
2. 等待处理中的任务完成：调用`awaitTermination`方法，这只需要指定超时时间
3. 超时未完成，强制关闭：调用`shutdownNow`方法

`ForkJoinPool`无法关闭，只能等待任务自动结束。

#### sofa-rpc运行时

运行时环境就是客户端，我们最开始已经说过了，各个组件中都有可能用到`rpc`客户端，所以将`rpc`客户端放到最后来销毁。

流程图如下：

![](https://syske-pic-bed.oss-cn-hangzhou.aliyuncs.com/imgs/0aa17c9e-9cc7-494b-8fb2-20fd474aab82.jpg)

核心流程也比较简单：
1. 找到运行时上下文`RpcRuntimeContext`
2. 调用上下文的`destroy`，完成销毁流程

至此，优雅关机的各个模块的核心方案流程我们已经分享完成，下面我们简单小结下。

## 小结

今天的内容我们主要分享了优雅关机的关键要点和各组件的关闭流程，通过上面的内容，想必大家对我们的优雅关机方案一定有了比较清晰的认识，总结来说，优雅关机的核心步骤有以下两点：
1. 关闭组件：这里的目的是让组件触发关闭流程，流程包括不接受新请求、新消息等
2. 等待：等待组件中的任务完成。这里面有个核心的点是监控，监控数据不仅能体现优雅关机效果，也作为是否需要继续等待的重要条件。

好了，今天的内容先到这里。各位小伙伴可以先思考下各个组件的监控要如何实现，下次分享揭晓答案哦
